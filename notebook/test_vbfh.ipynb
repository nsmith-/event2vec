{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb657d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from event2vec.datasets import VBFHDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ef1984",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = VBFHDataset.from_lhe(\"../data/smeftsim_VBFH-*.lhe.gz\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f71c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from event2vec.prior import SMPlusNormalParameterPrior\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "prior = SMPlusNormalParameterPrior(\n",
    "    # [\"cHbox\", \"cHDD\", \"cHW\", \"cHB\", \"cHWB\"]\n",
    "    mean=jnp.array([0.0, 0.0, 0.0, 0.0, 0.0]),\n",
    "    cov=jnp.diag(jnp.array([1.e+1, 1.e+1, 1.e-1, 1.e-1, 1.e+0])),\n",
    ")\n",
    "\n",
    "\n",
    "bins = jnp.linspace(0, 1000, 50)\n",
    "plt.hist(data.observables[:, -3], bins=bins, histtype=\"step\", color=\"k\", linewidth=2)\n",
    "plt.yscale(\"log\")\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    key = jax.random.PRNGKey(i)\n",
    "\n",
    "    plt.hist(\n",
    "        data.observables[:, -3],\n",
    "        weights=data.weight(prior.sample(key)),\n",
    "        bins=bins,\n",
    "        histtype=\"step\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4fc6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from event2vec.experiment import run_experiment\n",
    "from event2vec.model import E2VMLPConfig, CARLMLPConfig\n",
    "from event2vec.prior import UncorrelatedJointPrior\n",
    "from event2vec.training import TrainingConfig\n",
    "from event2vec.loss import BCELoss\n",
    "\n",
    "key = jax.random.PRNGKey(42)\n",
    "\n",
    "\n",
    "def data_factory(key):\n",
    "    return data\n",
    "\n",
    "\n",
    "model_config = CARLMLPConfig(\n",
    "    event_dim=data.observable_dim,\n",
    "    param_dim=data.parameter_dim,\n",
    "    hidden_size=64,\n",
    "    depth=3,\n",
    "    quadratic=True,\n",
    ")\n",
    "train_config = TrainingConfig(\n",
    "    test_fraction=0.1,\n",
    "    batch_size=64,\n",
    "    learning_rate=0.005,\n",
    "    epochs=1_000,\n",
    "    loss_fn=BCELoss(parameter_prior=UncorrelatedJointPrior(prior)),\n",
    ")\n",
    "\n",
    "# jax.config.update(\"jax_debug_nans\", True)\n",
    "\n",
    "model, data, loss_train, loss_test = run_experiment(\n",
    "    data_factory, model_config, train_config, key=key\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045ae596",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(loss_train, label=\"train loss\")\n",
    "ax.plot(loss_test, label=\"test loss\")\n",
    "ax.set_xlabel(\"Epoch\")\n",
    "ax.set_ylabel(\"Loss\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a829dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (axl, axr) = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "\n",
    "key = jax.random.PRNGKey(22)\n",
    "\n",
    "param_0 = jnp.array([1.0, 0.0, 0.0, 0.0, 0.0, 0.0])\n",
    "param_1 = prior.sample(key=key)\n",
    "print(\"Param 0:\", param_0)\n",
    "print(\"Param 1:\", param_1)\n",
    "\n",
    "llr_pred = jax.vmap(model.llr_pred, in_axes=(0, None, None))(data.observables, param_0, param_1)\n",
    "llr_true = jnp.log(data.likelihood(param_1)) - jnp.log(data.likelihood(param_0))\n",
    "\n",
    "amin = min(jnp.min(llr_pred).item(), jnp.min(llr_true).item())\n",
    "amax = max(jnp.max(llr_pred).item(), jnp.max(llr_true).item())\n",
    "axl.set_xlim(amin, amax)\n",
    "axl.set_ylim(amin, amax)\n",
    "axl.set_aspect(\"equal\")\n",
    "\n",
    "axl.plot([0, 1], [0, 1], color=\"grey\", linestyle=\"--\", transform=axl.transAxes)\n",
    "axl.scatter(llr_pred, llr_true, s=1)\n",
    "axl.set_xlabel(\"Predicted LLR\")\n",
    "axl.set_ylabel(\"True LLR\")\n",
    "p1short = \",\".join([f\"{p:.2f}\" for p in param_1])\n",
    "axl.set_title(fr\"$\\theta_1$: [{p1short}], $\\theta_0$: SM\")\n",
    "\n",
    "lr_true = jnp.exp(llr_true)\n",
    "lr_pred = jnp.exp(llr_pred)\n",
    "\n",
    "qbins = jnp.quantile(lr_pred, jnp.linspace(0, 1, 21))\n",
    "\n",
    "sumc, _ = jnp.histogram(lr_pred, bins=qbins)\n",
    "sumw, _ = jnp.histogram(lr_pred, bins=qbins, weights=lr_true)\n",
    "sumw2, _ = jnp.histogram(lr_pred, bins=qbins, weights=lr_true**2)\n",
    "\n",
    "mean = sumw / sumc\n",
    "std = jnp.sqrt(sumw2 / sumc - (sumw / sumc)**2)\n",
    "\n",
    "axr.errorbar(\n",
    "    0.5 * (qbins[1:] + qbins[:-1]),\n",
    "    mean,\n",
    "    xerr=0.5 * (qbins[1:] - qbins[:-1]),\n",
    "    yerr=std,\n",
    "    fmt=\"o\",\n",
    "    markersize=5,\n",
    "    capsize=3,\n",
    ")\n",
    "axr.plot([0, 1], [0, 1], color=\"grey\", linestyle=\"--\", transform=axr.transAxes)\n",
    "\n",
    "# axr.set_aspect(\"equal\")\n",
    "axr.set_xlabel(\"Predicted LR\")\n",
    "axr.set_ylabel(\"Mean true LR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3157be31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "event2vec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
